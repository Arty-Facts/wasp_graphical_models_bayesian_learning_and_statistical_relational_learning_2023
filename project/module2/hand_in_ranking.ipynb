{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdbe3b9f",
   "metadata": {},
   "source": [
    "# Probabilistic ranking\n",
    "In this part of the assignment you will analyze a data set consisting of tennis singles matches in the WTA 2013 Tour. (The data is adapted from https://github.com/JeffSackmann/tennis_wta, accessed on 2019-10-23.) The file `players.csv` contains a list of the top 260 players (according to their WTA ranking in June 2013) with unique player IDs, WTA rank and ranking points, name, and country. The list is sorted according to WTA rank. The file `matches2013.csv` contains a list of all matches played between these 260 top players, during the 2013 tour, with one match per row. The first column contains the ID of the winner of that match, and the second column contains the ID of the loser. **Note that, with this convention, the variable $y_k$ used in the lectures to define the model is one for all games: $y_k = 1$, $k=1, \\,  \\dots, \\, N$.**\n",
    "\n",
    "\n",
    "The task is to compute posterior player skills, using the (simplified version of the) TrueSkill model that we discussed in the lectures. We set the skill prior variance to $\\sigma_0^2 = 0.5$.\n",
    "\n",
    "First we import some useful packages and load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7af2822d",
   "metadata": {
    "id": "KMl1_qVBOYKE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "from tqdm import tqdm\n",
    "\n",
    "players_df = pd.read_csv(\"players.csv\")\n",
    "matches_df = pd.read_csv(\"matches2013.csv\")\n",
    "\n",
    "# Get arrays with the ID of winner and loser, respectively, for each match.\n",
    "# Subtract 1 to correspond with Python indexing (ID starts at 1 in players.csv)\n",
    "I_k = matches_df[\"winner_id\"].to_numpy() - 1\n",
    "J_k = matches_df[\"loser_id\"].to_numpy() - 1\n",
    "\n",
    "N = len(I_k) # Number of matches\n",
    "M = players_df.shape[0] # Number of players\n",
    "\n",
    "sigma2_0 = 0.5 # Skill prior variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dc00bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2459, 260)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N, M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326670d8",
   "metadata": {},
   "source": [
    "# Expectation propagation\n",
    "The first task is to implement an Expectation Propagation (EP) algorithm to solve the problem outlined above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4b5406",
   "metadata": {},
   "source": [
    "**Q1:** Let $\\mathbf{y}$ denote the observed data (i.e., a vector with the outcomes of the 260 played matches). Write down pseudo-code for the EP algorithm for approximating the posterior marginals over skill and performance variables,\n",
    "$$\n",
    "p(w_i \\mid \\mathbf{y}), \\quad i=1,\\,\\dots,\\,M, \\\\\n",
    "p(t_k \\mid \\mathbf{y}), \\quad k=1,\\,\\dots,\\,N.\n",
    "$$\n",
    "Write out explicit expressions for all the messages involved. Intractable messages should be approximated by Gaussian densities. Follow the steps outlined in the lecture (see specifically slides 30-36), starting with computing the skill marginals, followed by a downward pass and then a backward pass of messages.\n",
    "\t\t\n",
    "_Note: You may use both the standard form and the information form of the Gaussian messages: $N(\\mu, \\sigma^2) = N_I(\\nu,\\lambda)$. That is, when writing out the expression for the hyper-parameter update for each message, you can use the most convenient parameterization for that particular update, as long as it is clear from the notation which hyper-parameters that belong together. (For instance, write $\\mu_{f\\rightarrow x}$ and $\\nu_{f\\rightarrow x}$ to refer to the mean and natural mean of the message $m_{f\\rightarrow x}(x)$.)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cf2b29",
   "metadata": {},
   "source": [
    "#### step 0: Initialize game-to-skill messages\n",
    "\n",
    "$m_{g_i\\rightarrow w_i}(w_i) = N_I(0 ,0)$\n",
    "\n",
    "#### step 1: Update skill marginals\n",
    "$f_i(w_i) = N_I(w_i|0, \\frac{1}{0.5 ^2} )$\n",
    "\n",
    "$q(w_i) \\propto f_i(w_i) \\cdot \\prod_{\\forall k \\exists g_k \\rightarrow w_i} m_{g_k\\rightarrow w_i}(w_i) = N_I(w_i | 0+\\sum_{\\forall k \\exists g_k \\rightarrow w_i} \\nu_{g_k\\rightarrow w_i}, \\frac{1}{0.5 ^2}+\\sum_{\\forall k \\exists g_k \\rightarrow w_i} \\lambda_{g_k\\rightarrow w_i}) $\n",
    "\n",
    "#### Step 2: Compute skill-to-game messages\n",
    "$q(w_i) = N_I(w_i|\\nu_i, \\lambda_i )$\n",
    "\n",
    "$m_{w_i\\rightarrow g_k}(w_i) = \\frac{q(w_i)}{m_{g_k\\rightarrow w_i}(w_i)} =  N_I(w_i|\\nu_i - \\nu_{g_k\\rightarrow w_i}, \\lambda_i - \\lambda_{g_k\\rightarrow w_i} )$\n",
    "\n",
    "#### Step 3: Compute game-to-performance messages\n",
    "$g_k(t_k, w_{I_k}, w_{J_k}) = p(t_k | w_{I_k}, w_{J_k}) = N(t_k | w_{I_k} - w_{J_k} , 1) $\n",
    "\n",
    "$m_{g_k\\rightarrow t_k}(t_k) = \\int g_k(t_k, w_{I_k}, w_{J_k}) \\times m_{w_{I_k}\\rightarrow g_k}(w_{I_k}) m_{w_{J_k}\\rightarrow g_k}(w_{J_k}) d w_{I_k} w_{J_k} = $\n",
    "\n",
    "#### Step 4: Update performance marginals\n",
    "$h_k(t_k) = p(y_k | t_k ) = \\delta_{sign(t_k )}(y_k ) = \\mathbb{1}(y_k t_k > 0) $\n",
    "\n",
    "$\\pi(t_k) \\propto h_k(t_k) m_{g_k\\rightarrow t_k}(t_k) =  $ \n",
    "\n",
    "and approximate using moment matching,\n",
    "\n",
    "$q(t_k) \\approx \\pi(t_k) = $\n",
    "\n",
    "\n",
    "#### Step 5: Compute performance-to-game messages\n",
    "$m_{t_k\\rightarrow g_k}(t_k) = \\frac{q(t_k)}{m_{g_k\\rightarrow t_k}(t_k)} =  N_I(w_i|\\nu_i - \\nu_{g_k\\rightarrow t_k}, \\lambda_i - \\lambda_{g_k\\rightarrow t_k} )$\n",
    "\n",
    "\n",
    "#### Step 6: Compute game-to-skill messages\n",
    "$m_{g_k\\rightarrow w_{I_k}}(w_{I_k}) = \\int g_k(t_k, w_{I_k}, w_{J_k}) \\times m_{t_k\\rightarrow g_k}(t_k) m_{w_{J_k}\\rightarrow g_k}(w_{J_k}) d t_k w_{J_k} = $\n",
    "\n",
    "#### step 7: \n",
    "check for convergence xor go to step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f32844",
   "metadata": {},
   "source": [
    "**Q2:** In the lecture slides it is recommended to initialize the game-to-skill messages $m^{(0)}_{g_k\\rightarrow w_i}(w_i) \\equiv 1$ for $i \\in I_k \\cup J_k$.\n",
    "\n",
    "1. What does this imply for the skill marginals (computed in Step 1) at the first iteration of the algorithm, i.e. what will $q^{(1)}(w_i)$ correspond to?\n",
    "2. How can you implement $m^{(0)}_{g_k\\rightarrow w_i}(w_i) \\equiv 1$ in practice?\n",
    "\n",
    "_Hint: What should the message parameters correspond to in order to get the desired skill marginals, as identified in Q2.1?_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0a39ac",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a74f130f",
   "metadata": {},
   "source": [
    "**Q3:** Implement the EP message passing algorithm for the WTA data to approximate the posterior marginal skills $q(w_i) \\approx p(w_i \\mid \\mathbf{y})$, $i=1,\\,\\dots,\\,M$ and the posterior performance marginals $q(t_k) \\approx p(t_k \\mid \\mathbf{y})$, $k=1,\\,\\dots,\\,N$ by completing the code below. Plot the (approximations of) the posterior means $\\pm 1$ standard deviation vs player ID for the skills.\n",
    "\t\t\n",
    "_Note: For simplicity you are not required to implement a stopping criterion for the convergence of the algorithm (unless you want to!). It is sufficient to run it for a fixed number of iterations, say, 50._\n",
    "\t\t\n",
    "_Note: Use either the standard form or the information form parameterization of the Gaussian messages in the implementation, and transform between them when necessary._\n",
    "\t\t\n",
    "_Note: We have implemented a method for computing the moments of a truncated normal distribution for you. See e.g., the Wikipedia page on the truncated normal distribution for the expressions for the moments, https://en.wikipedia.org/wiki/Truncated_normal_distribution_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987f354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two helper functions used in the code below\n",
    "\n",
    "def switch_gaussian_parameterization(mu_or_nu, sigma2_or_lambda):\n",
    "    # Converts between standard and information form of normal distribuion\n",
    "    # Note that the \"conversion formulas\" are symmetric, so the same function\n",
    "    # can be used both ways:\n",
    "    #   mu = nu/lambda       nu = mu/sigma2\n",
    "    #   sigma2 = 1/lambda    lambda = 1/sigma2\n",
    "    assert (sigma2_or_lambda > 0).all(), \"0, Inf, or negative variance\"\n",
    "    return mu_or_nu/sigma2_or_lambda, 1/sigma2_or_lambda\n",
    "\n",
    "def get_truncated_params(mu, sigma2):\n",
    "    # Compute mean and variance of Gaussian truncated to positive real line \n",
    "    # N(x|mu_trunc,sigma2_trunc) \\approx 1{x>=0}*N(x|mu, sigma2) \n",
    "    sigma = np.sqrt(sigma2)\n",
    "    Z = 1 - st.norm.cdf(0, loc=mu, scale=sigma)\n",
    "    phi = st.norm.pdf(0, loc=mu, scale=sigma)\n",
    "    mu_trunc = mu + phi * sigma / Z\n",
    "    sigma2_trunc = sigma2 * (1 - (mu * phi / (sigma * Z)) - ((phi / Z) ** 2))\n",
    "    return mu_trunc, sigma2_trunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6cab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ITER_EP = 50\n",
    "\n",
    "# Message Passing\n",
    "# STEP 0: Initialize game to skill messages\n",
    "#  - Each game sends a message to both players in that game. How many \"g2w messages\" do we have?\n",
    "#  - The messages are Gaussian and we use the information form to represent these functions.\n",
    "#  - How should we initialize the messages? See Q2 above.\n",
    "#\n",
    "m_g2w_nu = ... # Natural means\n",
    "m_g2w_lambda = ... # Precisions\n",
    "\n",
    "for tau in tqdm(range(N_ITER_EP)):\n",
    "    # STEP 1: Update skill marginals\n",
    "    q_w_nu = ...\n",
    "    q_w_lambda = ...\n",
    "    for i, j, nu, lam in zip(I_k, J_k, m_g2w_nu, m_g2w_lambda):\n",
    "        # One way to implement this is to loop over all games and update the parameters of the skill marginals game-by-game\n",
    "        # (but you can of course implement this any way you want).\n",
    "        #\n",
    "        # i = first player in game k (winner according to our convention/sorting of data)\n",
    "        # j = second player in game k\n",
    "        # nu = natural mean of message sent from game k to the two participating players. Shape (2,) for winner/loser\n",
    "        # lam = precision of message sent from game k to the two participating players. Shape (2,) for winner/loser\n",
    "        \n",
    "        ...\n",
    "\n",
    "    # STEP 2: Skill to game messages\n",
    "    m_w2g_nu = ...\n",
    "    m_w2g_lambda = ...\n",
    "\n",
    "    # STEP 3: Game to performance messages\n",
    "    # Switch to standard parameterization to more easily carry out the \"convolution\" to compute these messages\n",
    "    m_w2g_mu, m_w2g_sigma2 = switch_gaussian_parameterization(m_w2g_nu, m_w2g_lambda)\n",
    "\n",
    "    m_g2t_mu = ...\n",
    "    m_g2t_sigma2 = ...\n",
    "\n",
    "    # STEP 4: Update performance marginals\n",
    "    # Note that h_k(t_k) = 1{t_k >= 0} for all t_k due to our convention that the winner is the first player\n",
    "    q_t_mu, q_t_sigma2 = get_truncated_params(m_g2t_mu, m_g2t_sigma2)\n",
    "    \n",
    "    # STEP 5: Performance to game messages\n",
    "    # Switch to information form to more easily be able to \"subtract information\"\n",
    "    q_t_nu, q_t_lambda = switch_gaussian_parameterization(q_t_mu, q_t_sigma2)\n",
    "    m_g2t_nu, m_g2t_lambda = switch_gaussian_parameterization(m_g2t_mu, m_g2t_sigma2)\n",
    "\n",
    "    m_t2g_nu = ...\n",
    "    m_t2g_lambda = ...\n",
    "\n",
    "    # STEP 6: Game to skill messages\n",
    "    # Switch to standard form to carry out convolution\n",
    "    m_t2g_mu, m_t2g_sigma2 = switch_gaussian_parameterization(m_t2g_nu, m_t2g_lambda)\n",
    "\n",
    "    m_g2w_mu = ...\n",
    "    m_g2w_sigma2 = ...\n",
    "\n",
    "    # Convert to information form for the next iteration\n",
    "    m_g2w_nu, m_g2w_lambda = switch_gaussian_parameterization(m_g2w_mu, m_g2w_sigma2)\n",
    "\n",
    "\n",
    "# Compute skill marginals on standard form    \n",
    "q_w_mu, q_w_sigma2 = switch_gaussian_parameterization(q_w_nu, q_w_lambda)\n",
    "q_w_sigma = np.sqrt(q_w_sigma2)\n",
    "\n",
    "# Plot posterior\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10,5))\n",
    "player_index = np.arange(M) +1\n",
    "ax.fill_between(player_index, q_w_mu - q_w_sigma, q_w_mu + q_w_sigma,\n",
    "        facecolor=\"blue\", alpha=0.5)\n",
    "ax.plot(player_index, q_w_mu, c=\"red\")\n",
    "ax.set_xlabel(\"Player ID\")\n",
    "ax.set_xlim(1, M)\n",
    "ax.set_ylabel(\"w\")\n",
    "ax.set_title(\"Posterior vs Player ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541f4bff",
   "metadata": {},
   "source": [
    "**Q4:**  Using the EP approximation derive an expression for the posterior probability (under the TrueSkill model) that Serena Williams beats Maria Sharapova. More specifically, let $y_\\text{new}$ be the outcome of a new match between these two players, where Williams is player 1 and Sharapove player 2. Then derive an expression for the probability,\n",
    "$$\n",
    " \\mathbb{P}(y_\\text{new} = 1 | \\mathbf{y}) = \\dots\n",
    "$$\n",
    "and show how this expression can be approximated (in a systematic way) using the output from the EP algorithm.\n",
    "\n",
    "_Hint: The EP algorithm is based on the \"mean field approximation\" which you need to use when approximating the probability above._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579b3090",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "977ad796",
   "metadata": {},
   "source": [
    "**Q5:** Approximate the probability above using the output from your EP algorithm. What is the estimated probability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57695017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute win prob\n",
    "willimas_id = 0 # ID of Williams (in Python indexing)\n",
    "sharapova_id = 1 # ID of Sharapova (in Python indexing)\n",
    "\n",
    "p_williams_beats_sharapova = ...\n",
    "print(f\"P(Willimas beats Shaparova) = {p_williams_beats_sharapova:.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6c64c3",
   "metadata": {},
   "source": [
    "# Gibbs sampler\n",
    "Next, we will implement a Gibbs sampler to solve the same problem and compare with the EP solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132dfc6e",
   "metadata": {},
   "source": [
    "**Q6:** Write down pseudo-code for a Gibbs sampler using the following Gibbs sweep:\n",
    "\t$$\n",
    "\t\t\\mathbf{w}' \\sim p(\\mathbf{w} \\mid \\mathbf{t}, \\mathbf{y}), \\\\\n",
    "\t\t\\mathbf{t}' \\sim p(\\mathbf{t} \\mid \\mathbf{w}', \\mathbf{y}).\n",
    "\t$$\n",
    "\tWrite out explicit expressions for the full conditionals. Which part(s) of the full conditionals can be precomputed outside the Gibbs loop?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c7a4c1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed8f2393",
   "metadata": {},
   "source": [
    "**Q7:** Based on the expressions that you have derived above, implement a Gibbs sampler on the WTA data to approximate the posterior distribution $p(\\mathbf{w},\\mathbf{t}\\mid\\mathbf{y})$ by completing the code below. Then answer the following questions:\n",
    "\n",
    "1. What is an appropriate number of iterations to run the sampler for? What does it mean for the sampler to \"converge\", i.e., what is the expected behavior in the long run?\n",
    "1. By visual inspection of the Gibbs iterations, what is an appropriate length of the _burn-in_ period?\n",
    "1. Plot the (approximations of) the posterior means $\\pm 1$ standard deviation for the skills vs player ID. Try to interpret the result!\n",
    "\n",
    "_Hint: Simulating from a truncated Gaussian distribution can be done using rejection sampling. Simply simulate from the non-truncated Gaussian, reject samples that fall outside the truncation interval, and keep simulating until you get a sample that falls in the truncation interval._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7390addd",
   "metadata": {
    "id": "hQ05R6siT0nP"
   },
   "outputs": [],
   "source": [
    "N_ITER_GIBBS = 1500 # Number of Gibbs iterations\n",
    "\n",
    "# Gibbs Sampler\n",
    "np.random.seed(123)\n",
    "\n",
    "w_trace = []\n",
    "t_trace = []\n",
    "\n",
    "# Initialize t\n",
    "t = np.zeros(N)\n",
    "\n",
    "for i in tqdm(range(N_ITER_GIBBS)):\n",
    "    # Sample w ~ p(w | t, y)    \n",
    "    ...\n",
    "    w = np.random.multivariate_normal(w_mean, Sigma)\n",
    "\n",
    "    # Sample t ~ p(t | w, y) using rejection sampling\n",
    "    t_mean = ... # (N,) array with mean of _untruncated_ distribution over variables t_k, k=1,...,N\n",
    "    t = np.zeros(N)\n",
    "    accept_mask = np.zeros(N).astype(bool) # All false\n",
    "    num_remaining = np.sum(~accept_mask)\n",
    "    while num_remaining > 0:        \n",
    "        # Sample from untruncated Gaussian, N(t_mean, 1), for the remaining matches\n",
    "        t[~accept_mask] = (np.random.randn(num_remaining) + t_mean[~accept_mask]) \n",
    "        accept_mask = (t >= 0)\n",
    "        num_remaining = np.sum(~accept_mask)\n",
    "\n",
    "    w_trace.append(w)\n",
    "    t_trace.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e24b90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "id": "q6JaL5M3nCg0",
    "outputId": "0a6ffb8a-17c5-43f4-a71c-2d2707b142fb"
   },
   "outputs": [],
   "source": [
    "# Plot the traces\n",
    "n_plot = 5 # We plot n_plot randomly selected players and matches, respectively\n",
    "plot_w_i = np.random.randint(0,M,size=n_plot)\n",
    "plot_t_i = np.random.randint(0,N,size=n_plot)\n",
    "\n",
    "w_trace = np.array(w_trace)\n",
    "t_trace = np.array(t_trace)\n",
    "plot_w_chains = w_trace[:,plot_w_i]\n",
    "plot_t_chains = t_trace[:,plot_t_i]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(15,10))\n",
    "for ax_i, chains, name in zip(ax, (plot_w_chains, plot_t_chains), (\"w\", \"t\")):\n",
    "    ax_i.plot(chains)\n",
    "    ax_i.set_ylabel(name)\n",
    "    ax_i.set_xlabel(\"iteration\")\n",
    "    ax_i.set_xlim(0, n_iter)\n",
    "\n",
    "fig.suptitle(\"Example sample chains\")\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34f392a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "g35E0lfTsLvB",
    "outputId": "23d2d11d-81be-4028-da2e-6ea564443646"
   },
   "outputs": [],
   "source": [
    "burn_in = ... # Set the burn-in based on the traces above\n",
    "\n",
    "# Compute posterior mean and standard deviation for player skills\n",
    "w_post_mean = ...\n",
    "w_post_std = ...\n",
    "\n",
    "# Plot the posterior player skills vs ID\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10,5))\n",
    "player_index = np.arange(M) +1\n",
    "ax.fill_between(player_index, w_post_mean - w_post_std, w_post_mean + w_post_std, facecolor=\"blue\", alpha=0.5)\n",
    "ax.plot(player_index, w_post_mean, c=\"red\")\n",
    "ax.set_xlabel(\"Player ID\")\n",
    "ax.set_xlim(1, M)\n",
    "ax.set_ylabel(\"w\")\n",
    "ax.set_title(\"Posterior vs Player ID\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79d512d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36f96b2c",
   "metadata": {},
   "source": [
    "**Q8:** Using the Gibbs approximation derive an expression for the posterior probability, under the TrueSkill model, that Serena Williams beats Maria Sharapova. More specifically, let $y_\\text{new}$ be the outcome of a new match between these two players, where Williams is player 1 and Sharapove player 2. Then derive an expression for the probability,\n",
    "$$\n",
    " \\mathbb{P}(y_\\text{new} = 1 | \\mathbf{y}) = \\dots\n",
    "$$\n",
    "and show how this expression can be approximated (in a systematic way) using the output from the Gibbs sampler.\n",
    "\n",
    "_Hint:_ The Gibbs sampler approximates the _joint posterior_ and you should leverage this property when approximating the probability above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de260152",
   "metadata": {},
   "source": [
    "**Q9:** Approximate the probability above using the output from your Gibbs sampler. What is the estimated probability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39f8873",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5EgEw3USz0mS",
    "outputId": "a545ecda-19c6-43a7-8fa2-3d21a575c5bf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute win prob\n",
    "willimas_id = 0 # ID of Williams (in Python indexing)\n",
    "sharapova_id = 1 # ID of Sharapova (in Python indexing)\n",
    "\n",
    "p_williams_beats_sharapova = ...\n",
    "\n",
    "print(f\"P(Willimas beats Shaparova) = {p_williams_beats_sharapova:.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cead9af7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
